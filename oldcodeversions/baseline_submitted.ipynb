{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/em-chiu/intersection_project/blob/main/EC%20Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DSgFvHzhSPNK",
    "outputId": "fe6a4603-759f-483e-b192-e891f58f83e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/emilychiu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/emilychiu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/emilychiu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import urllib.request\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "import string\n",
    "nltk.download('averaged_perceptron_tagger') # to solve pos feature extract issue\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import pandas as pd # data processing\n",
    "import csv\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import unidecode\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mQ8JQ1scSabd"
   },
   "outputs": [],
   "source": [
    "# load the data into list, try1\n",
    "\n",
    "# racistfile = open(\"FTR_new_labels.csv\", encoding='latin-1', \"r\")\n",
    "# racistdata = list(csv.reader(racistfile, delimiter=\",\"))\n",
    "# racistfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into list, try2\n",
    "# with open('FTR_new_labels.csv', newline='', encoding='latin-1') as csvfile:\n",
    "#     csv_reader = list(csv.reader(csvfile, delimiter='|'))\n",
    "#     print(csv_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# data_dir = '../data/'\n",
    "# or_fname = 'FTR_new_labels.csv'\n",
    "# fname = data_dir+or_fname\n",
    "\n",
    "\n",
    "# load the data to df, try1 works\n",
    "df = pd.read_csv('FTR_labels_copy.csv', header=None, encoding = \"ISO-8859-1\")\\\n",
    "        .drop(0, axis=1)\\\n",
    "        .rename(columns={1: 'tweet'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the data to df, try2\n",
    "# data = '/intersection_project/FTR_new_labels.csv'\n",
    "# df_racism = pd.read_csv(data, header=None, sep=',\\s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to convert to string\n",
    "# df_string = df.to_csv('FTR_new_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweet</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elle ne devait pas dÃ©gager la nazi ??? https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>je dois faire un oral en anglais sur Hitler et...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Par curiositÃ©, jâai voulu Ã©couter les dis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet      2\n",
       "0                                              tweet  label\n",
       "1  Elle ne devait pas dÃ©gager la nazi ??? https:...      1\n",
       "2  je dois faire un oral en anglais sur Hitler et...      0\n",
       "3  @ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...      0\n",
       "4  \"Par curiositÃ©, jâai voulu Ã©couter les dis...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop first row \n",
    "# by selecting all rows from first row onwards\n",
    "df = df.iloc[1: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2856, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view dimensions of dataset\n",
    "df.shape\n",
    "# 2857 instances and 2 attributes in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet', 'label'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename column names\n",
    "col_names = ['tweet', 'label']\n",
    "df.columns = col_names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elle ne devait pas dÃ©gager la nazi ??? https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>je dois faire un oral en anglais sur Hitler et...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Par curiositÃ©, jâai voulu Ã©couter les dis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@tical10 @ExBarcaFan74523 @ConflitsFrance Mdr ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet label\n",
       "1  Elle ne devait pas dÃ©gager la nazi ??? https:...     1\n",
       "2  je dois faire un oral en anglais sur Hitler et...     0\n",
       "3  @ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...     0\n",
       "4  \"Par curiositÃ©, jâai voulu Ã©couter les dis...     0\n",
       "5  @tical10 @ExBarcaFan74523 @ConflitsFrance Mdr ...     1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview after renaming\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2856 entries, 1 to 2856\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tweet   2856 non-null   object\n",
      " 1   label   2856 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 44.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# summary of data\n",
    "df.info()\n",
    "# no missing data\n",
    "# Categorical variables have data type object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 categorical variables\n",
      "\n",
      "The categorical variables are :\n",
      "\n",
      " ['tweet', 'label']\n"
     ]
    }
   ],
   "source": [
    "# find categorical variables\n",
    "categorical = [var for var in df.columns if df[var].dtype=='O']\n",
    "\n",
    "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "\n",
    "print('The categorical variables are :\\n\\n', categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elle ne devait pas dÃ©gager la nazi ??? https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>je dois faire un oral en anglais sur Hitler et...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Par curiositÃ©, jâai voulu Ã©couter les dis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@tical10 @ExBarcaFan74523 @ConflitsFrance Mdr ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet label\n",
       "1  Elle ne devait pas dÃ©gager la nazi ??? https:...     1\n",
       "2  je dois faire un oral en anglais sur Hitler et...     0\n",
       "3  @ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...     0\n",
       "4  \"Par curiositÃ©, jâai voulu Ã©couter les dis...     0\n",
       "5  @tical10 @ExBarcaFan74523 @ConflitsFrance Mdr ...     1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the categorical variables\n",
    "df[categorical].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet    0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in categorical variables\n",
    "df[categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"0. Moi\\n                                                                                                                                                    4\n",
      "@flo__lfc @leo2saucisson @ActuFoot_ CrÃ¨ve                                                                                                                   2\n",
      "\"ððððð\\n                                                                                                                                      2\n",
      "\"\"\"A Bright Room Called Day\"\", la cinglante leÃ§on d'histoire de Tony Kushner. Ma critique dans Les SoirÃ©es de Paris â¶ï¸Â https://t.co/Ydl1PqJv7AÂ \\n    2\n",
      "\"En ce moment sur LFM #CrÃ¨ve-cÅur#Mauvais Åil et toujours Le Morning sur LFM de 07h Ã  10h du Lundi au Vendredi.\\n                                        2\n",
      "                                                                                                                                                            ..\n",
      "de toutes faÃ§ons, c'est une mascarade. personne n'est mort et le masque sert Ã  rien #nazi #GiletsJaunes                                                    1\n",
      "Ah je crÃ¨ve de froid                                                                                                                                        1\n",
      "@Weatherboy_fr @ButchCoolidge11 @DamienRieu Bah oui câest les franÃ§ais qui ont Ã©lus hitler câest connuâ¦ gÃ©nie !                                     1\n",
      "@mormach Pitoyable cette information dirigÃ©e !!! On en crÃ¨ve !!!                                                                                           1\n",
      "Sal Noir https://t.co/9Sr7f4Mzr5 https://t.co/53F9rBpJsf                                                                                                     1\n",
      "Name: tweet, Length: 2847, dtype: int64\n",
      "0    1929\n",
      "1     927\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# view frequency counts of values in categorical variables\n",
    "for var in categorical: \n",
    "    print(df[var].value_counts())\n",
    "\n",
    "# 0        1929\n",
    "# 1         927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"0. Moi\\n                                                                                                                                                    0.001401\n",
      "@flo__lfc @leo2saucisson @ActuFoot_ CrÃ¨ve                                                                                                                   0.000700\n",
      "\"ððððð\\n                                                                                                                                      0.000700\n",
      "\"\"\"A Bright Room Called Day\"\", la cinglante leÃ§on d'histoire de Tony Kushner. Ma critique dans Les SoirÃ©es de Paris â¶ï¸Â https://t.co/Ydl1PqJv7AÂ \\n    0.000700\n",
      "\"En ce moment sur LFM #CrÃ¨ve-cÅur#Mauvais Åil et toujours Le Morning sur LFM de 07h Ã  10h du Lundi au Vendredi.\\n                                        0.000700\n",
      "                                                                                                                                                               ...   \n",
      "de toutes faÃ§ons, c'est une mascarade. personne n'est mort et le masque sert Ã  rien #nazi #GiletsJaunes                                                    0.000350\n",
      "Ah je crÃ¨ve de froid                                                                                                                                        0.000350\n",
      "@Weatherboy_fr @ButchCoolidge11 @DamienRieu Bah oui câest les franÃ§ais qui ont Ã©lus hitler câest connuâ¦ gÃ©nie !                                     0.000350\n",
      "@mormach Pitoyable cette information dirigÃ©e !!! On en crÃ¨ve !!!                                                                                           0.000350\n",
      "Sal Noir https://t.co/9Sr7f4Mzr5 https://t.co/53F9rBpJsf                                                                                                     0.000350\n",
      "Name: tweet, Length: 2847, dtype: float64\n",
      "0    0.67542\n",
      "1    0.32458\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# view frequency distribution of categorical variables\n",
    "for var in categorical:   \n",
    "    print(df[var].value_counts()/float(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1929\n",
       "1     927\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # check frequency distribution of values in label variable\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfobject=df.applymap(str)\n",
    "# print(dfobject.dtypes)\n",
    "# # convert df to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfstring=df.to_string\n",
    "# convert df to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datalist = df.values.tolist()\n",
    "# # data as list to feed into features functions\n",
    "# print(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tweet = df['tweet'].astype('string')\n",
    "# df_label = df['label'].astype('string')\n",
    "\n",
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet    object\n",
       "label    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .astype(str) and .astype('str') keep the column as object\n",
    "df_tweet = df['tweet'].astype(pd.StringDtype())\n",
    "df_label = df['label'].astype(pd.StringDtype())\n",
    "# https://stackoverflow.com/questions/60581893/convert-object-data-type-to-string-issue-in-python\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some entries were saved as float. This function gest rid of the problem.\n",
    "def to_string(text):\n",
    "    if type(text)==float:\n",
    "        text = str(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       Elle ne devait pas dÃ©gager la nazi ??? https:...\n",
       "2       je dois faire un oral en anglais sur Hitler et...\n",
       "3       @ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...\n",
       "4       \"Par curiositÃ©, jâai voulu Ã©couter les dis...\n",
       "5       @tical10 @ExBarcaFan74523 @ConflitsFrance Mdr ...\n",
       "                              ...                        \n",
       "2852                           Kevin câest un sal noir.\n",
       "2853    bougnoule bamboula sale arabe , elle est belle...\n",
       "2854      @B_mahrezz Tu viens de le traiter de sal noir ?\n",
       "2855                     SAL NOIR https://t.co/JraABFtel8\n",
       "2856    Sal Noir https://t.co/9Sr7f4Mzr5 https://t.co/...\n",
       "Name: tweet, Length: 2856, dtype: string"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colstr_tweet = to_string(df_tweet)\n",
    "colstr_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elle ne devait pas dÃ©gager la nazi ??? https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>je dois faire un oral en anglais sur Hitler et...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Par curiositÃ©, jâai voulu Ã©couter les dis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@tical10 @ExBarcaFan74523 @ConflitsFrance Mdr ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>Kevin câest un sal noir.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2853</th>\n",
       "      <td>bougnoule bamboula sale arabe , elle est belle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2854</th>\n",
       "      <td>@B_mahrezz Tu viens de le traiter de sal noir ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>SAL NOIR https://t.co/JraABFtel8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>Sal Noir https://t.co/9Sr7f4Mzr5 https://t.co/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2856 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet label\n",
       "1     Elle ne devait pas dÃ©gager la nazi ??? https:...     1\n",
       "2     je dois faire un oral en anglais sur Hitler et...     0\n",
       "3     @ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...     0\n",
       "4     \"Par curiositÃ©, jâai voulu Ã©couter les dis...     0\n",
       "5     @tical10 @ExBarcaFan74523 @ConflitsFrance Mdr ...     1\n",
       "...                                                 ...   ...\n",
       "2852                         Kevin câest un sal noir.     1\n",
       "2853  bougnoule bamboula sale arabe , elle est belle...     1\n",
       "2854    @B_mahrezz Tu viens de le traiter de sal noir ?     1\n",
       "2855                   SAL NOIR https://t.co/JraABFtel8     1\n",
       "2856  Sal Noir https://t.co/9Sr7f4Mzr5 https://t.co/...     1\n",
       "\n",
       "[2856 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringdf = to_string(df)\n",
    "stringdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "u4FcadFJSdXi"
   },
   "outputs": [],
   "source": [
    "# create a list of corresponding labels\n",
    "notracist_labels = [0] * 1929 # length of nonracist labels + header\n",
    "racist_labels = [1] * 927\n",
    "all_labels = notracist_labels + racist_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tweet = \" \".join(re.split(\"[^a-zA-Z]*\", text.lower())).strip()\n",
    "    return tweet.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mc/1k6qg5js1x31mqzdq17v2yym0000gn/T/ipykernel_59795/3020726862.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/mc/1k6qg5js1x31mqzdq17v2yym0000gn/T/ipykernel_59795/1389034414.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[^a-zA-Z]*\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "tokenize(to_string(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stopwords():\n",
    "    stopwords_en = nltk.corpus.stopwords.words(\"english\")\n",
    "    stopwords_fr = nltk.corpus.stopwords.words(\"french\")\n",
    "    stop_words = stopwords_en+stopwords_fr\n",
    "    other_exclusions = [\"les\"]\n",
    "    #stop_words.extend(other_exclusions)\n",
    "    return stop_words\n",
    "\n",
    "def remove_stopwords(text_list, sw):\n",
    "    return [word for word in text_list if word not in sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "-QHb6D8zSdNU"
   },
   "outputs": [],
   "source": [
    "# extract features: bag of stop words\n",
    "def remove_stopword(texts):\n",
    "    bow = [] \n",
    "    stopwords_en = stopwords.words('english')\n",
    "    stopwords_fr = nltk.corpus.stopwords.words(\"french\")\n",
    "    stop_words = stopwords_en+stopwords_fr\n",
    "    other_exclusions = [\"les\"]\n",
    "    for text in texts:      \n",
    "        counts = []\n",
    "        tokens = nltk.word_tokenize(text)#.lower()\n",
    "        for sw in stop_words:\n",
    "            sw_count = tokens.count(sw)\n",
    "            counts.append(sw_count)\n",
    "        bow.append(counts)\n",
    "    bow_np = np.array(bow).astype(float)\n",
    "    return bow_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "wZaIA5CnSdCn"
   },
   "outputs": [],
   "source": [
    "# extract features\n",
    "stopwords_features = remove_stopword(stringdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yzb-5l6L04Qs",
    "outputId": "7e6b602f-b136-47cd-c99b-3a8e8824ce30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 336)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_features.shape\n",
    "\n",
    "#(10, 336) why 336?!!\n",
    "#(2, 336) w/ df & stringdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DygmPc5pScsf",
    "outputId": "dc014358-a82b-4d0f-9e18-9100634c0beb"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 2856]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mc/1k6qg5js1x31mqzdq17v2yym0000gn/T/ipykernel_59795/344442507.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# report mean accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    446\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \"\"\"\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \"\"\"\n\u001b[1;32m    355\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    320\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 2856]"
     ]
    }
   ],
   "source": [
    "# convert features and labels to numpy arrays\n",
    "X = stopwords_features # count vectorizer\n",
    "Y = np.array(all_labels)\n",
    "\n",
    "# run classifier using 10-fold cross validation\n",
    "# report mean accuracy \n",
    "\n",
    "scores = cross_val_score(MultinomialNB(), X, Y, scoring='accuracy', cv=10)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVUr7eHcmxG0"
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "xE3_HfCe73kp"
   },
   "outputs": [],
   "source": [
    "# compile a RE into regex object to look for occurrences of same pattern inside target strings w/o rewriting it\n",
    "# ALF adds to data file\n",
    "def add_lexical_features(dataframe):\n",
    "    urls = re.compile(r\"http\")\n",
    "    ats = re.compile(r\"@[a-zA-Z.]*\")\n",
    "    hashtags = re.compile(r\"#[a-zA-Z]*\")\n",
    "    letters = re.compile(r\"[a-zA-Z]\")\n",
    "    caps = re.compile(r\"[A-Z]\")\n",
    "    fancy = [\";\",'\\\"','(','<<']\n",
    "\n",
    "    nbr_characters = [len(s) for s in df.tweet]\n",
    "    df['nbr_characters'] = pd.DataFrame(nbr_characters, index=df.index)\n",
    "\n",
    "    nbr_words = [len(s.split()) for s in df.tweet] # to update after cleaning\n",
    "    df['nbr_words'] = pd.Series(nbr_words, index=df.index)\n",
    "\n",
    "    nbr_ats = [len(ats.findall(text)) for text in df.tweet]\n",
    "    df['nbr_ats'] = pd.Series(nbr_ats, index=df.index)\n",
    "\n",
    "    nbr_hashtags = [len(hashtags.findall(text)) for text in df.tweet]\n",
    "    df['nbr_hashtags'] = pd.Series(nbr_hashtags, index=df.index)\n",
    "\n",
    "    nbr_urls = [len(urls.findall(text)) for text in df.tweet]\n",
    "    df['nbr_urls'] = pd.Series(nbr_urls, index=df.index)\n",
    "\n",
    "    nbr_letters = [len(letters.findall(text)) for text in df.tweet]\n",
    "    df['nbr_letters'] = pd.Series(nbr_letters, index=df.index)\n",
    "\n",
    "    nbr_caps = [len(caps.findall(text)) for text in df.tweet]\n",
    "    df['nbr_caps'] = pd.Series(nbr_caps, index=df.index)\n",
    "\n",
    "    nbr_fancy = [sum(1 for c in text if c in fancy) for text in df.tweet]\n",
    "    df['nbr_fancy'] = pd.Series(nbr_fancy, index=df.index)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "2KPQxp-u75wa"
   },
   "outputs": [],
   "source": [
    "# extract features\n",
    "lexical_features = add_lexical_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3UG_4wJ760u",
    "outputId": "c6981381-e2ab-4304-e814-9415e7b01095"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2856, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check size - 2856 tweets, 10 features\n",
    "lexical_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nGF7s4vb7703",
    "outputId": "9cb9c96b-78c8-4506-da2a-cfdead02d0da"
   },
   "outputs": [],
   "source": [
    "# convert features and labels to numpy arrays\n",
    "X = lexical_features\n",
    "Y = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>nbr_characters</th>\n",
       "      <th>nbr_words</th>\n",
       "      <th>nbr_ats</th>\n",
       "      <th>nbr_hashtags</th>\n",
       "      <th>nbr_urls</th>\n",
       "      <th>nbr_letters</th>\n",
       "      <th>nbr_caps</th>\n",
       "      <th>nbr_fancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2196</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2735</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1588</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>577</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2027</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet  label  nbr_characters  nbr_words  nbr_ats  nbr_hashtags  nbr_urls  \\\n",
       "1   2196      1              57          8        0             0         1   \n",
       "2   2735      0             103         18        0             0         0   \n",
       "3   1588      0              53         10        1             0         0   \n",
       "4    577      0             113         17        0             0         0   \n",
       "5   2027      1              82          9        3             0         0   \n",
       "\n",
       "   nbr_letters  nbr_caps  nbr_fancy  \n",
       "1           43         6          0  \n",
       "2           82         1          0  \n",
       "3           37         1          0  \n",
       "4           85         4          1  \n",
       "5           50         6          0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. INSTANTIATE\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# fit/transform\n",
    "# use df.apply() to apply le.fit_transform to all columns\n",
    "X_2 = X.apply(le.fit_transform)\n",
    "X_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_2, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2284, 10), (572, 10))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of X_train and X_test\n",
    "\n",
    "X_train.shape, X_test.shape\n",
    "# ((2284, 10), (572, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2284,), (572,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape\n",
    "# ((2284,), (572,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet             int64\n",
       "label             int64\n",
       "nbr_characters    int64\n",
       "nbr_words         int64\n",
       "nbr_ats           int64\n",
       "nbr_hashtags      int64\n",
       "nbr_urls          int64\n",
       "nbr_letters       int64\n",
       "nbr_caps          int64\n",
       "nbr_fancy         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data types in X_train\n",
    "\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display categorical variables\n",
    "categorical = [col for col in X_train.columns if X_train[col].dtypes == 'O']\n",
    "\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tweet',\n",
       " 'label',\n",
       " 'nbr_characters',\n",
       " 'nbr_words',\n",
       " 'nbr_ats',\n",
       " 'nbr_hashtags',\n",
       " 'nbr_urls',\n",
       " 'nbr_letters',\n",
       " 'nbr_caps',\n",
       " 'nbr_fancy']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display numerical variables\n",
    "numerical = [col for col in X_train.columns if X_train[col].dtypes != 'O']\n",
    "\n",
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print percentage of missing values in the categorical variables in training set\n",
    "X_train[categorical].isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in categorical variables in X_test\n",
    "X_test[categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [1587, 352, 1449, 2387, 2622]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[categorical].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # One-Hot encoding the categorical parameters using get_dummies() \n",
    "# one_hot_encoded_data = pd.get_dummies(df, columns = ['tweet', 'label'])\n",
    "# print(one_hot_encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode variables with one-hot encoding in preprocessing\n",
    "\n",
    "#df['tweet'] = le.fit_transform(df['tweet'])\n",
    "\n",
    "\n",
    "# X_train = encoder.fit_transform(X_train).toarray()\n",
    "# X_test = X_train = encoder.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>nbr_characters</th>\n",
       "      <th>nbr_words</th>\n",
       "      <th>nbr_ats</th>\n",
       "      <th>nbr_hashtags</th>\n",
       "      <th>nbr_urls</th>\n",
       "      <th>nbr_letters</th>\n",
       "      <th>nbr_caps</th>\n",
       "      <th>nbr_fancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>2110</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>2092</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>482</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>2843</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>2531</td>\n",
       "      <td>1</td>\n",
       "      <td>275</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet  label  nbr_characters  nbr_words  nbr_ats  nbr_hashtags  \\\n",
       "1587   2110      0              29          4        0             0   \n",
       "352    2092      1              75         12        0             0   \n",
       "1449    482      1             107         22        0             0   \n",
       "2387   2843      0             270         40        0             0   \n",
       "2622   2531      1             275         50        0             0   \n",
       "\n",
       "      nbr_urls  nbr_letters  nbr_caps  nbr_fancy  \n",
       "1587         0           13         3          0  \n",
       "352          1           60         4          0  \n",
       "1449         0           72         2          1  \n",
       "2387         1          210        56          0  \n",
       "2622         0          203         2          0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2284, 10)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>nbr_characters</th>\n",
       "      <th>nbr_words</th>\n",
       "      <th>nbr_ats</th>\n",
       "      <th>nbr_hashtags</th>\n",
       "      <th>nbr_urls</th>\n",
       "      <th>nbr_letters</th>\n",
       "      <th>nbr_caps</th>\n",
       "      <th>nbr_fancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>1551</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>2089</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>370</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>464</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>1006</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet  label  nbr_characters  nbr_words  nbr_ats  nbr_hashtags  \\\n",
       "2119   1551      0             191         24        3             0   \n",
       "2752   2089      0             106         12        1             1   \n",
       "1627    370      0              49          9        1             0   \n",
       "381     464      0              71         14        0             0   \n",
       "2356   1006      1              33          4        1             0   \n",
       "\n",
       "      nbr_urls  nbr_letters  nbr_caps  nbr_fancy  \n",
       "2119         0          140         6          0  \n",
       "2752         1           86        16          1  \n",
       "1627         0           40         1          1  \n",
       "381          0           59         2          1  \n",
       "2356         0           31        21          0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(572, 10)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model training\n",
    "# train a MNB classifier on the training set\n",
    "\n",
    "# instantiate the model\n",
    "MNB = MultinomialNB()\n",
    "\n",
    "\n",
    "# fit the model\n",
    "MNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5140252729726413\n"
     ]
    }
   ],
   "source": [
    "# run classifier using 10-fold cross validation\n",
    "# runs cross validation on dataset to test whether model can generalise over whole dataset\n",
    "# function returns list of one score per split, and average of scores can be calculated to provide a single metric value for dataset\n",
    "MNB_scores = cross_val_score(MultinomialNB(), X_2, Y, scoring='accuracy', cv=10)\n",
    "print(MNB_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting results\n",
    "y_pred = MNB.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score: 0.4755\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "#checking accuracy score\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n",
    "# y_test are true class labels and y_pred are predicted class labels in test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-set accuracy score: 0.5070\n"
     ]
    }
   ],
   "source": [
    "# compare the train-set and test-set accuracy to check for overfitting\n",
    "y_pred_train = MNB.predict(X_train)\n",
    "y_pred_train\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.5070\n",
      "Test set score: 0.4755\n"
     ]
    }
   ],
   "source": [
    "# print the scores on training and test set\n",
    "print('Training set score: {:.4f}'.format(MNB.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(MNB.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare against null accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[176 200]\n",
      " [100  96]]\n",
      "\n",
      "True Positives(TP) =  176\n",
      "\n",
      "True Negatives(TN) =  96\n",
      "\n",
      "False Positives(FP) =  200\n",
      "\n",
      "False Negatives(FN) =  100\n"
     ]
    }
   ],
   "source": [
    "# Print the Confusion Matrix and slice it into four pieces\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize confusion matrix with seaborn heatmap\n",
    "\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.47      0.54       376\n",
      "           1       0.32      0.49      0.39       196\n",
      "\n",
      "    accuracy                           0.48       572\n",
      "   macro avg       0.48      0.48      0.47       572\n",
      "weighted avg       0.53      0.48      0.49       572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report to evaluate the classification model performance\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = cm[0,0]\n",
    "TN = cm[1,1]\n",
    "FP = cm[0,1]\n",
    "FN = cm[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy : 0.4755\n"
     ]
    }
   ],
   "source": [
    "# print classification accuracy, same as test set score & model accuracy score\n",
    "\n",
    "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
    "print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification error : 0.5245\n"
     ]
    }
   ],
   "source": [
    "# print classification error\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print('Classification error : {0:0.4f}'.format(classification_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.390\n"
     ]
    }
   ],
   "source": [
    "# f1-score is always lower than accuracy measures, they embed precision and recall into their computation\n",
    "print('F1 Score: %.3f' % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
