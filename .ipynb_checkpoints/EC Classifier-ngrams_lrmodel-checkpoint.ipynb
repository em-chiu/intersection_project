{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/em-chiu/intersection_project/blob/main/EC%20Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DSgFvHzhSPNK",
    "outputId": "fe6a4603-759f-483e-b192-e891f58f83e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/emilychiu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/emilychiu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/emilychiu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import urllib.request\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "import string\n",
    "nltk.download('averaged_perceptron_tagger') # to solve pos feature extract issue\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import pandas as pd # data processing\n",
    "import csv\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import unidecode\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mQ8JQ1scSabd"
   },
   "outputs": [],
   "source": [
    "# load the data into list, try1\n",
    "\n",
    "# racistfile = open(\"FTR_new_labels.csv\", encoding='latin-1', \"r\")\n",
    "# racistdata = list(csv.reader(racistfile, delimiter=\",\"))\n",
    "# racistfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into list, try2\n",
    "# with open('FTR_new_labels.csv', newline='', encoding='latin-1') as csvfile:\n",
    "#     csv_reader = list(csv.reader(csvfile, delimiter='|'))\n",
    "#     print(csv_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# data_dir = '../data/'\n",
    "# or_fname = 'FTR_new_labels.csv'\n",
    "# fname = data_dir+or_fname\n",
    "\n",
    "\n",
    "# load the data to df, try1 works\n",
    "df = pd.read_csv('FTR_labels_copy.csv', header=None, encoding = \"ISO-8859-1\")\\\n",
    "        .drop(0, axis=1)\\\n",
    "        .rename(columns={1: 'tweet'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the data to df, try2\n",
    "# data = '/intersection_project/FTR_new_labels.csv'\n",
    "# df_racism = pd.read_csv(data, header=None, sep=',\\s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to convert to string\n",
    "# df_string = df.to_csv('FTR_new_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweet</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elle ne devait pas dÃ©gager la nazi ??? https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>je dois faire un oral en anglais sur Hitler et...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Par curiositÃ©, jâai voulu Ã©couter les dis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet      2\n",
       "0                                              tweet  label\n",
       "1  Elle ne devait pas dÃ©gager la nazi ??? https:...      1\n",
       "2  je dois faire un oral en anglais sur Hitler et...      0\n",
       "3  @ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...      0\n",
       "4  \"Par curiositÃ©, jâai voulu Ã©couter les dis...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop first row \n",
    "# by selecting all rows from first row onwards\n",
    "df = df.iloc[1: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2856, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view dimensions of dataset\n",
    "df.shape\n",
    "# 2857 instances and 2 attributes in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet', 'label'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename column names\n",
    "col_names = ['tweet', 'label']\n",
    "df.columns = col_names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elle ne devait pas dÃ©gager la nazi ??? https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>je dois faire un oral en anglais sur Hitler et...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Par curiositÃ©, jâai voulu Ã©couter les dis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@tical10 @ExBarcaFan74523 @ConflitsFrance Mdr ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet label\n",
       "1  Elle ne devait pas dÃ©gager la nazi ??? https:...     1\n",
       "2  je dois faire un oral en anglais sur Hitler et...     0\n",
       "3  @ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...     0\n",
       "4  \"Par curiositÃ©, jâai voulu Ã©couter les dis...     0\n",
       "5  @tical10 @ExBarcaFan74523 @ConflitsFrance Mdr ...     1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview after renaming\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2856 entries, 1 to 2856\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tweet   2856 non-null   object\n",
      " 1   label   2856 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 44.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# summary of data\n",
    "df.info()\n",
    "# no missing data\n",
    "# Categorical variables have data type object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 categorical variables\n",
      "\n",
      "The categorical variables are :\n",
      "\n",
      " ['tweet', 'label']\n"
     ]
    }
   ],
   "source": [
    "# find categorical variables\n",
    "categorical = [var for var in df.columns if df[var].dtype=='O']\n",
    "\n",
    "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "\n",
    "print('The categorical variables are :\\n\\n', categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elle ne devait pas dÃ©gager la nazi ??? https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>je dois faire un oral en anglais sur Hitler et...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Par curiositÃ©, jâai voulu Ã©couter les dis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@tical10 @ExBarcaFan74523 @ConflitsFrance Mdr ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet label\n",
       "1  Elle ne devait pas dÃ©gager la nazi ??? https:...     1\n",
       "2  je dois faire un oral en anglais sur Hitler et...     0\n",
       "3  @ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...     0\n",
       "4  \"Par curiositÃ©, jâai voulu Ã©couter les dis...     0\n",
       "5  @tical10 @ExBarcaFan74523 @ConflitsFrance Mdr ...     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the categorical variables\n",
    "df[categorical].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet    0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in categorical variables\n",
    "df[categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"0. Moi\\n                                                                                                                                                    4\n",
      "@flo__lfc @leo2saucisson @ActuFoot_ CrÃ¨ve                                                                                                                   2\n",
      "\"ððððð\\n                                                                                                                                      2\n",
      "\"\"\"A Bright Room Called Day\"\", la cinglante leÃ§on d'histoire de Tony Kushner. Ma critique dans Les SoirÃ©es de Paris â¶ï¸Â https://t.co/Ydl1PqJv7AÂ \\n    2\n",
      "\"En ce moment sur LFM #CrÃ¨ve-cÅur#Mauvais Åil et toujours Le Morning sur LFM de 07h Ã  10h du Lundi au Vendredi.\\n                                        2\n",
      "                                                                                                                                                            ..\n",
      "de toutes faÃ§ons, c'est une mascarade. personne n'est mort et le masque sert Ã  rien #nazi #GiletsJaunes                                                    1\n",
      "Ah je crÃ¨ve de froid                                                                                                                                        1\n",
      "@Weatherboy_fr @ButchCoolidge11 @DamienRieu Bah oui câest les franÃ§ais qui ont Ã©lus hitler câest connuâ¦ gÃ©nie !                                     1\n",
      "@mormach Pitoyable cette information dirigÃ©e !!! On en crÃ¨ve !!!                                                                                           1\n",
      "Sal Noir https://t.co/9Sr7f4Mzr5 https://t.co/53F9rBpJsf                                                                                                     1\n",
      "Name: tweet, Length: 2847, dtype: int64\n",
      "0    1929\n",
      "1     927\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# view frequency counts of values in categorical variables\n",
    "for var in categorical: \n",
    "    print(df[var].value_counts())\n",
    "\n",
    "# 0        1929\n",
    "# 1         927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"0. Moi\\n                                                                                                                                                    0.001401\n",
      "@flo__lfc @leo2saucisson @ActuFoot_ CrÃ¨ve                                                                                                                   0.000700\n",
      "\"ððððð\\n                                                                                                                                      0.000700\n",
      "\"\"\"A Bright Room Called Day\"\", la cinglante leÃ§on d'histoire de Tony Kushner. Ma critique dans Les SoirÃ©es de Paris â¶ï¸Â https://t.co/Ydl1PqJv7AÂ \\n    0.000700\n",
      "\"En ce moment sur LFM #CrÃ¨ve-cÅur#Mauvais Åil et toujours Le Morning sur LFM de 07h Ã  10h du Lundi au Vendredi.\\n                                        0.000700\n",
      "                                                                                                                                                               ...   \n",
      "de toutes faÃ§ons, c'est une mascarade. personne n'est mort et le masque sert Ã  rien #nazi #GiletsJaunes                                                    0.000350\n",
      "Ah je crÃ¨ve de froid                                                                                                                                        0.000350\n",
      "@Weatherboy_fr @ButchCoolidge11 @DamienRieu Bah oui câest les franÃ§ais qui ont Ã©lus hitler câest connuâ¦ gÃ©nie !                                     0.000350\n",
      "@mormach Pitoyable cette information dirigÃ©e !!! On en crÃ¨ve !!!                                                                                           0.000350\n",
      "Sal Noir https://t.co/9Sr7f4Mzr5 https://t.co/53F9rBpJsf                                                                                                     0.000350\n",
      "Name: tweet, Length: 2847, dtype: float64\n",
      "0    0.67542\n",
      "1    0.32458\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# view frequency distribution of categorical variables\n",
    "for var in categorical:   \n",
    "    print(df[var].value_counts()/float(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1929\n",
       "1     927\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # check frequency distribution of values in label variable\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfobject=df.applymap(str)\n",
    "# print(dfobject.dtypes)\n",
    "# # convert df to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfstring=df.to_string\n",
    "# convert df to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datalist = df.values.tolist()\n",
    "# # data as list to feed into features functions\n",
    "# print(datalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet    object\n",
       "label    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_tweet = df['tweet'].astype('string')\n",
    "# df_label = df['label'].astype('string')\n",
    "\n",
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet    object\n",
       "label    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .astype(str) and .astype('str') keep the column as object\n",
    "df_tweet = df['tweet'].astype(pd.StringDtype())\n",
    "df_label = df['label'].astype(pd.StringDtype())\n",
    "# https://stackoverflow.com/questions/60581893/convert-object-data-type-to-string-issue-in-python\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some entries were saved as float. This function gest rid of the problem.\n",
    "def to_string(text):\n",
    "    if type(text)==float:\n",
    "        text = str(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       Elle ne devait pas dÃ©gager la nazi ??? https:...\n",
       "2       je dois faire un oral en anglais sur Hitler et...\n",
       "3       @ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...\n",
       "4       \"Par curiositÃ©, jâai voulu Ã©couter les dis...\n",
       "5       @tical10 @ExBarcaFan74523 @ConflitsFrance Mdr ...\n",
       "                              ...                        \n",
       "2852                           Kevin câest un sal noir.\n",
       "2853    bougnoule bamboula sale arabe , elle est belle...\n",
       "2854      @B_mahrezz Tu viens de le traiter de sal noir ?\n",
       "2855                     SAL NOIR https://t.co/JraABFtel8\n",
       "2856    Sal Noir https://t.co/9Sr7f4Mzr5 https://t.co/...\n",
       "Name: tweet, Length: 2856, dtype: string"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colstr_tweet = to_string(df_tweet)\n",
    "colstr_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elle ne devait pas dÃ©gager la nazi ??? https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>je dois faire un oral en anglais sur Hitler et...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Par curiositÃ©, jâai voulu Ã©couter les dis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@tical10 @ExBarcaFan74523 @ConflitsFrance Mdr ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>Kevin câest un sal noir.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2853</th>\n",
       "      <td>bougnoule bamboula sale arabe , elle est belle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2854</th>\n",
       "      <td>@B_mahrezz Tu viens de le traiter de sal noir ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>SAL NOIR https://t.co/JraABFtel8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>Sal Noir https://t.co/9Sr7f4Mzr5 https://t.co/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2856 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet label\n",
       "1     Elle ne devait pas dÃ©gager la nazi ??? https:...     1\n",
       "2     je dois faire un oral en anglais sur Hitler et...     0\n",
       "3     @ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...     0\n",
       "4     \"Par curiositÃ©, jâai voulu Ã©couter les dis...     0\n",
       "5     @tical10 @ExBarcaFan74523 @ConflitsFrance Mdr ...     1\n",
       "...                                                 ...   ...\n",
       "2852                         Kevin câest un sal noir.     1\n",
       "2853  bougnoule bamboula sale arabe , elle est belle...     1\n",
       "2854    @B_mahrezz Tu viens de le traiter de sal noir ?     1\n",
       "2855                   SAL NOIR https://t.co/JraABFtel8     1\n",
       "2856  Sal Noir https://t.co/9Sr7f4Mzr5 https://t.co/...     1\n",
       "\n",
       "[2856 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringdf = to_string(df)\n",
    "stringdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "u4FcadFJSdXi"
   },
   "outputs": [],
   "source": [
    "# create a list of corresponding labels\n",
    "notracist_labels = [0] * 1929 # length of nonracist labels + header\n",
    "racist_labels = [1] * 927\n",
    "all_labels = notracist_labels + racist_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tweet = \" \".join(re.split(\"[^a-zA-Z]*\", text.lower())).strip()\n",
    "    return tweet.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mc/1k6qg5js1x31mqzdq17v2yym0000gn/T/ipykernel_58337/3020726862.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/mc/1k6qg5js1x31mqzdq17v2yym0000gn/T/ipykernel_58337/1389034414.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[^a-zA-Z]*\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "tokenize(to_string(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stopwords():\n",
    "    stopwords_en = nltk.corpus.stopwords.words(\"english\")\n",
    "    stopwords_fr = nltk.corpus.stopwords.words(\"french\")\n",
    "    stop_words = stopwords_en+stopwords_fr\n",
    "    other_exclusions = [\"les\"]\n",
    "    #stop_words.extend(other_exclusions)\n",
    "    return stop_words\n",
    "\n",
    "def remove_stopwords(text_list, sw):\n",
    "    return [word for word in text_list if word not in sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "-QHb6D8zSdNU"
   },
   "outputs": [],
   "source": [
    "# extract features: bag of stop words\n",
    "def remove_stopword(texts):\n",
    "    bow = [] \n",
    "    stopwords_en = stopwords.words('english')\n",
    "    stopwords_fr = nltk.corpus.stopwords.words(\"french\")\n",
    "    stop_words = stopwords_en+stopwords_fr\n",
    "    other_exclusions = [\"les\"]\n",
    "    for text in texts:      \n",
    "        counts = []\n",
    "        tokens = nltk.word_tokenize(text)#.lower()\n",
    "        for sw in stop_words:\n",
    "            sw_count = tokens.count(sw)\n",
    "            counts.append(sw_count)\n",
    "        bow.append(counts)\n",
    "    bow_np = np.array(bow).astype(float)\n",
    "    return bow_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "wZaIA5CnSdCn"
   },
   "outputs": [],
   "source": [
    "# extract features\n",
    "stopwords_features = remove_stopword(stringdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yzb-5l6L04Qs",
    "outputId": "7e6b602f-b136-47cd-c99b-3a8e8824ce30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 336)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_features.shape\n",
    "\n",
    "#(10, 336) why 336?!!\n",
    "#(2, 336) w/ df & stringdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DygmPc5pScsf",
    "outputId": "dc014358-a82b-4d0f-9e18-9100634c0beb"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 2856]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mc/1k6qg5js1x31mqzdq17v2yym0000gn/T/ipykernel_58337/344442507.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# report mean accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    446\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \"\"\"\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \"\"\"\n\u001b[1;32m    355\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    320\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 2856]"
     ]
    }
   ],
   "source": [
    "# convert features and labels to numpy arrays\n",
    "X = stopwords_features # count vectorizer\n",
    "Y = np.array(all_labels)\n",
    "\n",
    "# run classifier using 10-fold cross validation\n",
    "# report mean accuracy \n",
    "\n",
    "scores = cross_val_score(MultinomialNB(), X, Y, scoring='accuracy', cv=10)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVUr7eHcmxG0"
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "xE3_HfCe73kp"
   },
   "outputs": [],
   "source": [
    "# compile a RE into regex object to look for occurrences of same pattern inside target strings w/o rewriting it\n",
    "# ALF adds to data file\n",
    "def add_lexical_features(dataframe):\n",
    "    urls = re.compile(r\"http\")\n",
    "    ats = re.compile(r\"@[a-zA-Z.]*\")\n",
    "    hashtags = re.compile(r\"#[a-zA-Z]*\")\n",
    "    letters = re.compile(r\"[a-zA-Z]\")\n",
    "    caps = re.compile(r\"[A-Z]\")\n",
    "    fancy = [\";\",'\\\"','(','<<']\n",
    "\n",
    "    nbr_characters = [len(s) for s in df.tweet]\n",
    "    df['nbr_characters'] = pd.DataFrame(nbr_characters, index=df.index)\n",
    "\n",
    "    nbr_words = [len(s.split()) for s in df.tweet] # to update after cleaning\n",
    "    df['nbr_words'] = pd.Series(nbr_words, index=df.index)\n",
    "\n",
    "    nbr_ats = [len(ats.findall(text)) for text in df.tweet]\n",
    "    df['nbr_ats'] = pd.Series(nbr_ats, index=df.index)\n",
    "\n",
    "    nbr_hashtags = [len(hashtags.findall(text)) for text in df.tweet]\n",
    "    df['nbr_hashtags'] = pd.Series(nbr_hashtags, index=df.index)\n",
    "\n",
    "    nbr_urls = [len(urls.findall(text)) for text in df.tweet]\n",
    "    df['nbr_urls'] = pd.Series(nbr_urls, index=df.index)\n",
    "\n",
    "    nbr_letters = [len(letters.findall(text)) for text in df.tweet]\n",
    "    df['nbr_letters'] = pd.Series(nbr_letters, index=df.index)\n",
    "\n",
    "    nbr_caps = [len(caps.findall(text)) for text in df.tweet]\n",
    "    df['nbr_caps'] = pd.Series(nbr_caps, index=df.index)\n",
    "\n",
    "    nbr_fancy = [sum(1 for c in text if c in fancy) for text in df.tweet]\n",
    "    df['nbr_fancy'] = pd.Series(nbr_fancy, index=df.index)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "2KPQxp-u75wa"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mc/1k6qg5js1x31mqzdq17v2yym0000gn/T/ipykernel_58337/2345239809.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# extract features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlexical_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_lexical_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/mc/1k6qg5js1x31mqzdq17v2yym0000gn/T/ipykernel_58337/2899827145.py\u001b[0m in \u001b[0;36madd_lexical_features\u001b[0;34m(dataframe)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfancy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\\"'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'('\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'<<'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mnbr_characters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nbr_characters'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbr_characters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/mc/1k6qg5js1x31mqzdq17v2yym0000gn/T/ipykernel_58337/2899827145.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mfancy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\";\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\\"'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'('\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'<<'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mnbr_characters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nbr_characters'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbr_characters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "# extract features\n",
    "lexical_features = add_lexical_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3UG_4wJ760u",
    "outputId": "c6981381-e2ab-4304-e814-9415e7b01095"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2856, 10)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check size - 2856 tweets, 10 features\n",
    "lexical_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nGF7s4vb7703",
    "outputId": "9cb9c96b-78c8-4506-da2a-cfdead02d0da"
   },
   "outputs": [],
   "source": [
    "# convert features and labels to numpy arrays\n",
    "X = lexical_features\n",
    "Y = np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>nbr_characters</th>\n",
       "      <th>nbr_words</th>\n",
       "      <th>nbr_ats</th>\n",
       "      <th>nbr_hashtags</th>\n",
       "      <th>nbr_urls</th>\n",
       "      <th>nbr_letters</th>\n",
       "      <th>nbr_caps</th>\n",
       "      <th>nbr_fancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2196</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2735</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1588</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>577</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2027</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet  label  nbr_characters  nbr_words  nbr_ats  nbr_hashtags  nbr_urls  \\\n",
       "1   2196      1              57          8        0             0         1   \n",
       "2   2735      0             103         18        0             0         0   \n",
       "3   1588      0              53         10        1             0         0   \n",
       "4    577      0             113         17        0             0         0   \n",
       "5   2027      1              82          9        3             0         0   \n",
       "\n",
       "   nbr_letters  nbr_caps  nbr_fancy  \n",
       "1           43         6          0  \n",
       "2           82         1          0  \n",
       "3           37         1          0  \n",
       "4           85         4          1  \n",
       "5           50         6          0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. INSTANTIATE\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# fit/transform\n",
    "# use df.apply() to apply le.fit_transform to all columns\n",
    "X_2 = X.apply(le.fit_transform)\n",
    "X_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2284, 10), (572, 10))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of X_train and X_test\n",
    "\n",
    "X_train.shape, X_test.shape\n",
    "# ((2284, 10), (572, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2284,), (572,))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape\n",
    "# ((2284,), (572,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet              int64\n",
       "label             object\n",
       "nbr_characters     int64\n",
       "nbr_words          int64\n",
       "nbr_ats            int64\n",
       "nbr_hashtags       int64\n",
       "nbr_urls           int64\n",
       "nbr_letters        int64\n",
       "nbr_caps           int64\n",
       "nbr_fancy          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data types in X_train\n",
    "\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display categorical variables\n",
    "categorical = [col for col in X_train.columns if X_train[col].dtypes == 'O']\n",
    "\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nbr_characters',\n",
       " 'nbr_words',\n",
       " 'nbr_ats',\n",
       " 'nbr_hashtags',\n",
       " 'nbr_urls',\n",
       " 'nbr_letters',\n",
       " 'nbr_caps',\n",
       " 'nbr_fancy']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display numerical variables\n",
    "numerical = [col for col in X_train.columns if X_train[col].dtypes != 'O']\n",
    "\n",
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet    0.0\n",
       "label    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print percentage of missing values in the categorical variables in training set\n",
    "X_train[categorical].isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet    0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in categorical variables in X_test\n",
    "X_test[categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>BTS en traje negro ðððð</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Alors xavier ca fait quoi de se faire niquer p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>\"Donc tâes lÃ  tu aimes , Ã©lÃ¨ve une fille ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>â­L'INSISTANCE ds neoliberaux pr LEUR technol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>Pas que je sois folle mais on vit sous le rÃ©g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet label\n",
       "1587                BTS en traje negro ðððð     0\n",
       "352   Alors xavier ca fait quoi de se faire niquer p...     1\n",
       "1449  \"Donc tâes lÃ  tu aimes , Ã©lÃ¨ve une fille ...     1\n",
       "2387  â­L'INSISTANCE ds neoliberaux pr LEUR technol...     0\n",
       "2622  Pas que je sois folle mais on vit sous le rÃ©g...     1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[categorical].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # One-Hot encoding the categorical parameters using get_dummies() \n",
    "# one_hot_encoded_data = pd.get_dummies(df, columns = ['tweet', 'label'])\n",
    "# print(one_hot_encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode variables with one-hot encoding in preprocessing\n",
    "\n",
    "#df['tweet'] = le.fit_transform(df['tweet'])\n",
    "\n",
    "\n",
    "# X_train = encoder.fit_transform(X_train).toarray()\n",
    "# X_test = X_train = encoder.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>nbr_characters</th>\n",
       "      <th>nbr_words</th>\n",
       "      <th>nbr_ats</th>\n",
       "      <th>nbr_hashtags</th>\n",
       "      <th>nbr_urls</th>\n",
       "      <th>nbr_letters</th>\n",
       "      <th>nbr_caps</th>\n",
       "      <th>nbr_fancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>BTS en traje negro ðððð</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Alors xavier ca fait quoi de se faire niquer p...</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>\"Donc tâes lÃ  tu aimes , Ã©lÃ¨ve une fille ...</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>â­L'INSISTANCE ds neoliberaux pr LEUR technol...</td>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>213</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>Pas que je sois folle mais on vit sous le rÃ©g...</td>\n",
       "      <td>1</td>\n",
       "      <td>287</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet label  nbr_characters  \\\n",
       "1587                BTS en traje negro ðððð     0              35   \n",
       "352   Alors xavier ca fait quoi de se faire niquer p...     1              81   \n",
       "1449  \"Donc tâes lÃ  tu aimes , Ã©lÃ¨ve une fille ...     1             113   \n",
       "2387  â­L'INSISTANCE ds neoliberaux pr LEUR technol...     0             282   \n",
       "2622  Pas que je sois folle mais on vit sous le rÃ©g...     1             287   \n",
       "\n",
       "      nbr_words  nbr_ats  nbr_hashtags  nbr_urls  nbr_letters  nbr_caps  \\\n",
       "1587          5        0             0         0           15         3   \n",
       "352          13        0             0         1           62         4   \n",
       "1449         23        0             0         0           74         2   \n",
       "2387         41        0             0         1          213        89   \n",
       "2622         51        0             0         0          205         2   \n",
       "\n",
       "      nbr_fancy  \n",
       "1587          0  \n",
       "352           0  \n",
       "1449          1  \n",
       "2387          0  \n",
       "2622          0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2284, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>nbr_characters</th>\n",
       "      <th>nbr_words</th>\n",
       "      <th>nbr_ats</th>\n",
       "      <th>nbr_hashtags</th>\n",
       "      <th>nbr_urls</th>\n",
       "      <th>nbr_letters</th>\n",
       "      <th>nbr_caps</th>\n",
       "      <th>nbr_fancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>@_MarcoPolo___ @nfaure_ @omorley3 Absurde: Hit...</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>Alain Soral analyse l'affaire de Toulouse (Aff...</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>\"@luizfalvesjr Il y a plus de fautes dans votr...</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>\"Comment tu veux faire la guerre au Maroc alor...</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>@GilbertCollard LA DIGNE FILLE D'HITLER</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet label  nbr_characters  \\\n",
       "2119  @_MarcoPolo___ @nfaure_ @omorley3 Absurde: Hit...     0             197   \n",
       "2752  Alain Soral analyse l'affaire de Toulouse (Aff...     0             112   \n",
       "1627  \"@luizfalvesjr Il y a plus de fautes dans votr...     0              55   \n",
       "381   \"Comment tu veux faire la guerre au Maroc alor...     0              77   \n",
       "2356            @GilbertCollard LA DIGNE FILLE D'HITLER     1              39   \n",
       "\n",
       "      nbr_words  nbr_ats  nbr_hashtags  nbr_urls  nbr_letters  nbr_caps  \\\n",
       "2119         25        3             0         0          142         6   \n",
       "2752         13        1             1         1           88        16   \n",
       "1627         10        1             0         0           42         1   \n",
       "381          15        0             0         0           61         2   \n",
       "2356          5        1             0         0           33        21   \n",
       "\n",
       "      nbr_fancy  \n",
       "2119          0  \n",
       "2752          1  \n",
       "1627          1  \n",
       "381           1  \n",
       "2356          0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(572, 10)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model training\n",
    "# train a MNB classifier on the training set\n",
    "\n",
    "# instantiate the model\n",
    "MNB = MultinomialNB()\n",
    "\n",
    "\n",
    "# fit the model\n",
    "MNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5157759784075574\n"
     ]
    }
   ],
   "source": [
    "# run classifier using 10-fold cross validation\n",
    "# runs cross validation on dataset to test whether model can generalise over whole dataset\n",
    "# function returns list of one score per split, and average of scores can be calculated to provide a single metric value for dataset\n",
    "MNB_scores = cross_val_score(MultinomialNB(), X, Y, scoring='accuracy', cv=10)\n",
    "print(MNB_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting results\n",
    "y_pred = MNB.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score: 0.4773\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "#checking accuracy score\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n",
    "# y_test are true class labels and y_pred are predicted class labels in test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-set accuracy score: 0.5079\n"
     ]
    }
   ],
   "source": [
    "# compare the train-set and test-set accuracy to check for overfitting\n",
    "y_pred_train = MNB.predict(X_train)\n",
    "y_pred_train\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.5079\n",
      "Test set score: 0.4773\n"
     ]
    }
   ],
   "source": [
    "# print the scores on training and test set\n",
    "print('Training set score: {:.4f}'.format(MNB.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(MNB.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare against null accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[177 199]\n",
      " [100  96]]\n",
      "\n",
      "True Positives(TP) =  177\n",
      "\n",
      "True Negatives(TN) =  96\n",
      "\n",
      "False Positives(FP) =  199\n",
      "\n",
      "False Negatives(FN) =  100\n"
     ]
    }
   ],
   "source": [
    "# Print the Confusion Matrix and slice it into four pieces\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize confusion matrix with seaborn heatmap\n",
    "\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.47      0.54       376\n",
      "           1       0.33      0.49      0.39       196\n",
      "\n",
      "    accuracy                           0.48       572\n",
      "   macro avg       0.48      0.48      0.47       572\n",
      "weighted avg       0.53      0.48      0.49       572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report to evaluate the classification model performance\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = cm[0,0]\n",
    "TN = cm[1,1]\n",
    "FP = cm[0,1]\n",
    "FN = cm[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy : 0.4773\n"
     ]
    }
   ],
   "source": [
    "# print classification accuracy, same as test set score & model accuracy score\n",
    "\n",
    "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
    "print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification error : 0.5227\n"
     ]
    }
   ],
   "source": [
    "# print classification error\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print('Classification error : {0:0.4f}'.format(classification_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.391\n"
     ]
    }
   ],
   "source": [
    "# f1-score is always lower than accuracy measures, they embed precision and recall into their computation\n",
    "print('F1 Score: %.3f' % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
