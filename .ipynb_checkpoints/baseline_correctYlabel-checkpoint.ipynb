{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/em-chiu/intersection_project/blob/main/EC%20Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DSgFvHzhSPNK",
    "outputId": "fe6a4603-759f-483e-b192-e891f58f83e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/emilychiu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/emilychiu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import urllib.request\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "import string\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import pandas as pd # data processing\n",
    "import csv\n",
    "import sys\n",
    "import unidecode\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data to df, try1 works\n",
    "df = pd.read_csv('FTR_labels_base.csv', header=None, encoding = \"ISO-8859-1\")\\\n",
    "        .drop(0, axis=1)\\\n",
    "        .rename(columns={1: 'tweet'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweet</td>\n",
       "      <td>label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elle ne devait pas dÃ©gager la nazi ??? https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>je dois faire un oral en anglais sur Hitler et...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Par curiositÃ©, jâai voulu Ã©couter les dis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet      2\n",
       "0                                              tweet  label\n",
       "1  Elle ne devait pas dÃ©gager la nazi ??? https:...      1\n",
       "2  je dois faire un oral en anglais sur Hitler et...      0\n",
       "3  @ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...      0\n",
       "4  \"Par curiositÃ©, jâai voulu Ã©couter les dis...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop first row \n",
    "# by selecting all rows from first row onwards\n",
    "df = df.iloc[1: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2856, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view dimensions of dataset\n",
    "df.shape\n",
    "# 2857 instances and 2 attributes in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet', 'label'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename column names\n",
    "col_names = ['tweet', 'label']\n",
    "df.columns = col_names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elle ne devait pas dÃ©gager la nazi ??? https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>je dois faire un oral en anglais sur Hitler et...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Par curiositÃ©, jâai voulu Ã©couter les dis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@tical10 @ExBarcaFan74523 @ConflitsFrance Mdr ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet label\n",
       "1  Elle ne devait pas dÃ©gager la nazi ??? https:...     1\n",
       "2  je dois faire un oral en anglais sur Hitler et...     0\n",
       "3  @ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...     0\n",
       "4  \"Par curiositÃ©, jâai voulu Ã©couter les dis...     0\n",
       "5  @tical10 @ExBarcaFan74523 @ConflitsFrance Mdr ...     1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview after renaming\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2856 entries, 1 to 2856\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tweet   2856 non-null   object\n",
      " 1   label   2856 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 44.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# summary of data\n",
    "df.info()\n",
    "# no missing data\n",
    "# Categorical variables have data type object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 categorical variables\n",
      "\n",
      "The categorical variables are :\n",
      "\n",
      " ['tweet', 'label']\n"
     ]
    }
   ],
   "source": [
    "# find categorical variables\n",
    "categorical = [var for var in df.columns if df[var].dtype=='O']\n",
    "\n",
    "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "\n",
    "print('The categorical variables are :\\n\\n', categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elle ne devait pas dÃ©gager la nazi ??? https:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>je dois faire un oral en anglais sur Hitler et...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Par curiositÃ©, jâai voulu Ã©couter les dis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@tical10 @ExBarcaFan74523 @ConflitsFrance Mdr ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet label\n",
       "1  Elle ne devait pas dÃ©gager la nazi ??? https:...     1\n",
       "2  je dois faire un oral en anglais sur Hitler et...     0\n",
       "3  @ambrassmoi_ A Ã§a ð¤ de ressembler Ã  la cr...     0\n",
       "4  \"Par curiositÃ©, jâai voulu Ã©couter les dis...     0\n",
       "5  @tical10 @ExBarcaFan74523 @ConflitsFrance Mdr ...     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the categorical variables\n",
    "df[categorical].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet    0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in categorical variables\n",
    "df[categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"0. Moi\\n                                                                                                                                                    4\n",
      "@flo__lfc @leo2saucisson @ActuFoot_ CrÃ¨ve                                                                                                                   2\n",
      "\"ððððð\\n                                                                                                                                      2\n",
      "\"\"\"A Bright Room Called Day\"\", la cinglante leÃ§on d'histoire de Tony Kushner. Ma critique dans Les SoirÃ©es de Paris â¶ï¸Â https://t.co/Ydl1PqJv7AÂ \\n    2\n",
      "\"En ce moment sur LFM #CrÃ¨ve-cÅur#Mauvais Åil et toujours Le Morning sur LFM de 07h Ã  10h du Lundi au Vendredi.\\n                                        2\n",
      "                                                                                                                                                            ..\n",
      "de toutes faÃ§ons, c'est une mascarade. personne n'est mort et le masque sert Ã  rien #nazi #GiletsJaunes                                                    1\n",
      "Ah je crÃ¨ve de froid                                                                                                                                        1\n",
      "@Weatherboy_fr @ButchCoolidge11 @DamienRieu Bah oui câest les franÃ§ais qui ont Ã©lus hitler câest connuâ¦ gÃ©nie !                                     1\n",
      "@mormach Pitoyable cette information dirigÃ©e !!! On en crÃ¨ve !!!                                                                                           1\n",
      "Sal Noir https://t.co/9Sr7f4Mzr5 https://t.co/53F9rBpJsf                                                                                                     1\n",
      "Name: tweet, Length: 2847, dtype: int64\n",
      "0    1929\n",
      "1     927\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# view frequency counts of values in categorical variables\n",
    "for var in categorical: \n",
    "    print(df[var].value_counts())\n",
    "\n",
    "# 0        1929\n",
    "# 1         927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"0. Moi\\n                                                                                                                                                    0.001401\n",
      "@flo__lfc @leo2saucisson @ActuFoot_ CrÃ¨ve                                                                                                                   0.000700\n",
      "\"ððððð\\n                                                                                                                                      0.000700\n",
      "\"\"\"A Bright Room Called Day\"\", la cinglante leÃ§on d'histoire de Tony Kushner. Ma critique dans Les SoirÃ©es de Paris â¶ï¸Â https://t.co/Ydl1PqJv7AÂ \\n    0.000700\n",
      "\"En ce moment sur LFM #CrÃ¨ve-cÅur#Mauvais Åil et toujours Le Morning sur LFM de 07h Ã  10h du Lundi au Vendredi.\\n                                        0.000700\n",
      "                                                                                                                                                               ...   \n",
      "de toutes faÃ§ons, c'est une mascarade. personne n'est mort et le masque sert Ã  rien #nazi #GiletsJaunes                                                    0.000350\n",
      "Ah je crÃ¨ve de froid                                                                                                                                        0.000350\n",
      "@Weatherboy_fr @ButchCoolidge11 @DamienRieu Bah oui câest les franÃ§ais qui ont Ã©lus hitler câest connuâ¦ gÃ©nie !                                     0.000350\n",
      "@mormach Pitoyable cette information dirigÃ©e !!! On en crÃ¨ve !!!                                                                                           0.000350\n",
      "Sal Noir https://t.co/9Sr7f4Mzr5 https://t.co/53F9rBpJsf                                                                                                     0.000350\n",
      "Name: tweet, Length: 2847, dtype: float64\n",
      "0    0.67542\n",
      "1    0.32458\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# view frequency distribution of categorical variables\n",
    "for var in categorical:   \n",
    "    print(df[var].value_counts()/float(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1929\n",
       "1     927\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # check frequency distribution of values in label variable\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet    object\n",
       "label    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .astype(str) and .astype('str') keep the column as object\n",
    "df_tweet = df['tweet'].astype(pd.StringDtype())\n",
    "# elements in df are str (dataframe containing str)\n",
    "df_label = df['label'].astype(pd.StringDtype())\n",
    "# https://stackoverflow.com/questions/60581893/convert-object-data-type-to-string-issue-in-python\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stopwords():\n",
    "    stopwords_en = nltk.corpus.stopwords.words(\"english\")\n",
    "    stopwords_fr = nltk.corpus.stopwords.words(\"french\")\n",
    "    stop_words = stopwords_en+stopwords_fr\n",
    "    other_exclusions = [\"les\"]\n",
    "    #stop_words.extend(other_exclusions)\n",
    "    return stop_words\n",
    "\n",
    "def remove_stopwords(text_list, sw):\n",
    "    return [word for word in text_list if word not in sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = list(df['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "xE3_HfCe73kp"
   },
   "outputs": [],
   "source": [
    "# compile a RE into regex object to look for occurrences of same pattern inside target strings w/o rewriting it\n",
    "# ALF adds to data file\n",
    "def add_lexical_features(dataframe):\n",
    "    urls = re.compile(r\"http\")\n",
    "    ats = re.compile(r\"@[a-zA-Z.]*\")\n",
    "    hashtags = re.compile(r\"#[a-zA-Z]*\")\n",
    "    letters = re.compile(r\"[a-zA-Z]\")\n",
    "    caps = re.compile(r\"[A-Z]\")\n",
    "    fancy = [\";\",'\\\"','(','<<']\n",
    "\n",
    "    nbr_characters = [len(s) for s in df.tweet]\n",
    "    df['nbr_characters'] = pd.DataFrame(nbr_characters, index=df.index)\n",
    "\n",
    "    nbr_words = [len(s.split()) for s in df.tweet] # to update after cleaning\n",
    "    df['nbr_words'] = pd.Series(nbr_words, index=df.index)\n",
    "\n",
    "    nbr_ats = [len(ats.findall(text)) for text in df.tweet]\n",
    "    df['nbr_ats'] = pd.Series(nbr_ats, index=df.index)\n",
    "\n",
    "    nbr_hashtags = [len(hashtags.findall(text)) for text in df.tweet]\n",
    "    df['nbr_hashtags'] = pd.Series(nbr_hashtags, index=df.index)\n",
    "\n",
    "    nbr_urls = [len(urls.findall(text)) for text in df.tweet]\n",
    "    df['nbr_urls'] = pd.Series(nbr_urls, index=df.index)\n",
    "\n",
    "    nbr_letters = [len(letters.findall(text)) for text in df.tweet]\n",
    "    df['nbr_letters'] = pd.Series(nbr_letters, index=df.index)\n",
    "\n",
    "    nbr_caps = [len(caps.findall(text)) for text in df.tweet]\n",
    "    df['nbr_caps'] = pd.Series(nbr_caps, index=df.index)\n",
    "\n",
    "    nbr_fancy = [sum(1 for c in text if c in fancy) for text in df.tweet]\n",
    "    df['nbr_fancy'] = pd.Series(nbr_fancy, index=df.index)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "2KPQxp-u75wa"
   },
   "outputs": [],
   "source": [
    "# extract features\n",
    "lexical_features = add_lexical_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3UG_4wJ760u",
    "outputId": "c6981381-e2ab-4304-e814-9415e7b01095"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2856, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check size - 2856 tweets, 10 features\n",
    "lexical_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nGF7s4vb7703",
    "outputId": "9cb9c96b-78c8-4506-da2a-cfdead02d0da"
   },
   "outputs": [],
   "source": [
    "# convert features and labels to numpy arrays\n",
    "X = lexical_features\n",
    "Y = df['label'] # list of labels of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>nbr_characters</th>\n",
       "      <th>nbr_words</th>\n",
       "      <th>nbr_ats</th>\n",
       "      <th>nbr_hashtags</th>\n",
       "      <th>nbr_urls</th>\n",
       "      <th>nbr_letters</th>\n",
       "      <th>nbr_caps</th>\n",
       "      <th>nbr_fancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2196</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2735</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1588</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>577</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2027</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet  label  nbr_characters  nbr_words  nbr_ats  nbr_hashtags  nbr_urls  \\\n",
       "1   2196      1              57          8        0             0         1   \n",
       "2   2735      0             103         18        0             0         0   \n",
       "3   1588      0              53         10        1             0         0   \n",
       "4    577      0             113         17        0             0         0   \n",
       "5   2027      1              82          9        3             0         0   \n",
       "\n",
       "   nbr_letters  nbr_caps  nbr_fancy  \n",
       "1           43         6          0  \n",
       "2           82         1          0  \n",
       "3           37         1          0  \n",
       "4           85         4          1  \n",
       "5           50         6          0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode target label\n",
    "# Label Encoding is converting labels/words into numeric form. \n",
    "# #Label encoding doesn't affect the dimensionality of the data set.\n",
    "\n",
    "# INSTANTIATE\n",
    "le = preprocessing.LabelEncoder()\n",
    "# fit/transform, encoding df\n",
    "# use df.apply() to apply le.fit_transform to all columns\n",
    "X_2 = X.apply(le.fit_transform)\n",
    "X_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_2, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10, 2284]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mc/1k6qg5js1x31mqzdq17v2yym0000gn/T/ipykernel_78626/2157019478.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# train naive bayes classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# create predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \"\"\"\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_class_log_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_prior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    320\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10, 2284]"
     ]
    }
   ],
   "source": [
    "# n gram feature\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# counts the number of times a token shows up in the document and uses this value as its weight\n",
    "# create a bag of words for only unigrams\n",
    "cv = CountVectorizer(analyzer = 'word',ngram_range=(1,1), stop_words='english')\n",
    "# # create a bag of words for with unigrams and bigrams\n",
    "# cv = CountVectorizer(analyzer = 'word',ngram_range=(1,2), stop_words='english')\n",
    "\n",
    "# convert training data to bag of words\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)\n",
    "\n",
    "# train naive bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_cv, y_train)\n",
    "\n",
    "# create predictions\n",
    "y_pred = clf.predict(X_test_cv)\n",
    "\n",
    "# find f-1 score\n",
    "score = f1_score(y_test, y_pred, average='macro')\n",
    "print('F-1 score : {}'.format(np.round(score,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2284, 10), (572, 10))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of X_train and X_test\n",
    "\n",
    "X_train.shape, X_test.shape\n",
    "# ((2284, 10), (572, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2284,), (572,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape\n",
    "# ((2284,), (572,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet             int64\n",
       "label             int64\n",
       "nbr_characters    int64\n",
       "nbr_words         int64\n",
       "nbr_ats           int64\n",
       "nbr_hashtags      int64\n",
       "nbr_urls          int64\n",
       "nbr_letters       int64\n",
       "nbr_caps          int64\n",
       "nbr_fancy         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data types in X_train\n",
    "\n",
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display categorical variables\n",
    "categorical = [col for col in X_train.columns if X_train[col].dtypes == 'O']\n",
    "\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tweet',\n",
       " 'label',\n",
       " 'nbr_characters',\n",
       " 'nbr_words',\n",
       " 'nbr_ats',\n",
       " 'nbr_hashtags',\n",
       " 'nbr_urls',\n",
       " 'nbr_letters',\n",
       " 'nbr_caps',\n",
       " 'nbr_fancy']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display numerical variables\n",
    "numerical = [col for col in X_train.columns if X_train[col].dtypes != 'O']\n",
    "\n",
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print percentage of missing values in the categorical variables in training set\n",
    "X_train[categorical].isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: float64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values in categorical variables in X_test\n",
    "X_test[categorical].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [1587, 352, 1449, 2387, 2622]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[categorical].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>nbr_characters</th>\n",
       "      <th>nbr_words</th>\n",
       "      <th>nbr_ats</th>\n",
       "      <th>nbr_hashtags</th>\n",
       "      <th>nbr_urls</th>\n",
       "      <th>nbr_letters</th>\n",
       "      <th>nbr_caps</th>\n",
       "      <th>nbr_fancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>2110</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>2092</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>482</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>2843</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>2531</td>\n",
       "      <td>1</td>\n",
       "      <td>275</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet  label  nbr_characters  nbr_words  nbr_ats  nbr_hashtags  \\\n",
       "1587   2110      0              29          4        0             0   \n",
       "352    2092      1              75         12        0             0   \n",
       "1449    482      1             107         22        0             0   \n",
       "2387   2843      0             270         40        0             0   \n",
       "2622   2531      1             275         50        0             0   \n",
       "\n",
       "      nbr_urls  nbr_letters  nbr_caps  nbr_fancy  \n",
       "1587         0           13         3          0  \n",
       "352          1           60         4          0  \n",
       "1449         0           72         2          1  \n",
       "2387         1          210        56          0  \n",
       "2622         0          203         2          0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2284, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>nbr_characters</th>\n",
       "      <th>nbr_words</th>\n",
       "      <th>nbr_ats</th>\n",
       "      <th>nbr_hashtags</th>\n",
       "      <th>nbr_urls</th>\n",
       "      <th>nbr_letters</th>\n",
       "      <th>nbr_caps</th>\n",
       "      <th>nbr_fancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>1551</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2752</th>\n",
       "      <td>2089</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>370</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>464</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>1006</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet  label  nbr_characters  nbr_words  nbr_ats  nbr_hashtags  \\\n",
       "2119   1551      0             191         24        3             0   \n",
       "2752   2089      0             106         12        1             1   \n",
       "1627    370      0              49          9        1             0   \n",
       "381     464      0              71         14        0             0   \n",
       "2356   1006      1              33          4        1             0   \n",
       "\n",
       "      nbr_urls  nbr_letters  nbr_caps  nbr_fancy  \n",
       "2119         0          140         6          0  \n",
       "2752         1           86        16          1  \n",
       "1627         0           40         1          1  \n",
       "381          0           59         2          1  \n",
       "2356         0           31        21          0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(572, 10)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model training\n",
    "# train a MNB classifier on the training set\n",
    "\n",
    "# instantiate the model\n",
    "MNB = MultinomialNB()\n",
    "\n",
    "\n",
    "# fit the model\n",
    "MNB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5777426082689241\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# run classifier using 10-fold cross validation\n",
    "# runs cross validation on dataset to test whether model can generalise over whole dataset\n",
    "# function returns list of one score per split, and average of scores can be calculated to provide a single metric value for dataset\n",
    "MNB_scores = cross_val_score(MultinomialNB(), X_2, Y, scoring='accuracy', cv=10)\n",
    "print(MNB_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '0', '0', '1', '1', '0', '1', '1', '1', '0', '1', '1',\n",
       "       '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '0',\n",
       "       '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1',\n",
       "       '1', '1', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0',\n",
       "       '0', '0', '0', '1', '0', '1', '1', '1', '0', '1', '1', '0', '1',\n",
       "       '0', '0', '1', '1', '0', '1', '1', '0', '0', '1', '1', '0', '1',\n",
       "       '1', '1', '1', '0', '0', '0', '1', '1', '1', '1', '0', '1', '1',\n",
       "       '1', '1', '0', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1',\n",
       "       '1', '0', '0', '0', '0', '1', '1', '0', '0', '1', '0', '1', '0',\n",
       "       '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '1', '1', '1',\n",
       "       '1', '0', '1', '1', '0', '0', '0', '0', '1', '1', '1', '0', '0',\n",
       "       '0', '0', '1', '0', '1', '0', '1', '1', '1', '0', '1', '0', '0',\n",
       "       '0', '0', '1', '1', '0', '1', '1', '1', '0', '1', '0', '1', '1',\n",
       "       '1', '1', '0', '0', '1', '1', '1', '0', '1', '1', '0', '0', '0',\n",
       "       '1', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '0', '0', '1', '0', '0', '0', '1', '0',\n",
       "       '1', '1', '0', '1', '1', '1', '0', '1', '0', '0', '1', '1', '0',\n",
       "       '1', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1',\n",
       "       '0', '1', '1', '0', '1', '1', '1', '0', '1', '1', '0', '1', '0',\n",
       "       '0', '1', '1', '0', '1', '1', '0', '0', '1', '0', '1', '1', '0',\n",
       "       '0', '1', '0', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0',\n",
       "       '1', '1', '1', '0', '1', '1', '1', '0', '1', '1', '0', '1', '1',\n",
       "       '1', '0', '1', '0', '0', '0', '1', '0', '0', '1', '1', '1', '1',\n",
       "       '0', '1', '1', '0', '0', '0', '1', '1', '1', '0', '0', '1', '1',\n",
       "       '0', '0', '1', '1', '0', '1', '0', '0', '0', '1', '1', '0', '1',\n",
       "       '1', '1', '1', '1', '0', '1', '0', '0', '1', '1', '0', '0', '1',\n",
       "       '0', '1', '0', '0', '1', '0', '0', '1', '1', '1', '0', '0', '0',\n",
       "       '1', '1', '0', '0', '1', '0', '0', '0', '0', '1', '0', '1', '1',\n",
       "       '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '1', '1',\n",
       "       '1', '0', '0', '1', '1', '1', '0', '1', '1', '1', '0', '1', '1',\n",
       "       '1', '0', '0', '1', '0', '1', '0', '1', '0', '1', '0', '0', '0',\n",
       "       '1', '0', '0', '1', '0', '0', '0', '0', '1', '1', '1', '1', '0',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '1', '1', '0',\n",
       "       '0', '0', '0', '1', '1', '0', '1', '1', '1', '1', '0', '1', '0',\n",
       "       '1', '1', '0', '1', '1', '1', '0', '1', '0', '1', '0', '0', '0',\n",
       "       '1', '1', '1', '0', '0', '1', '1', '1', '1', '0', '0', '1', '1',\n",
       "       '1', '1', '1', '0', '1', '0', '1', '0', '1', '0', '0', '0', '0',\n",
       "       '0', '1', '1', '0', '1', '0', '1', '0', '1', '1', '1', '0', '1',\n",
       "       '1', '1', '0', '1', '1', '1', '1', '1', '1', '0', '1', '0', '1',\n",
       "       '1', '0', '0', '0', '1', '0', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '0', '1', '0', '0', '1', '0', '0', '1', '0', '0', '1', '0', '0',\n",
       "       '1', '1', '0', '0', '0', '1', '0', '1', '1', '0', '0', '0', '0',\n",
       "       '1', '0', '0', '1', '0', '0', '0', '0', '1', '1', '1', '1', '1',\n",
       "       '1', '0', '0', '1', '1', '1', '0', '1', '0', '0', '1', '0', '1'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting results\n",
    "y_pred = MNB.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score: 0.5629\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "#checking accuracy score\n",
    "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n",
    "# y_test are true class labels and y_pred are predicted class labels in test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-set accuracy score: 0.5788\n"
     ]
    }
   ],
   "source": [
    "# compare the train-set and test-set accuracy to check for overfitting\n",
    "y_pred_train = MNB.predict(X_train)\n",
    "y_pred_train\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.5788\n",
      "Test set score: 0.5629\n"
     ]
    }
   ],
   "source": [
    "# print the scores on training and test set\n",
    "print('Training set score: {:.4f}'.format(MNB.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(MNB.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare against null accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[201 189]\n",
      " [ 61 121]]\n",
      "\n",
      "True Positives(TP) =  201\n",
      "\n",
      "True Negatives(TN) =  121\n",
      "\n",
      "False Positives(FP) =  189\n",
      "\n",
      "False Negatives(FN) =  61\n"
     ]
    }
   ],
   "source": [
    "# Print the Confusion Matrix and slice it into four pieces\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize confusion matrix with seaborn heatmap\n",
    "\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.52      0.62       390\n",
      "           1       0.39      0.66      0.49       182\n",
      "\n",
      "    accuracy                           0.56       572\n",
      "   macro avg       0.58      0.59      0.55       572\n",
      "weighted avg       0.65      0.56      0.58       572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report to evaluate the classification model performance\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = cm[0,0]\n",
    "TN = cm[1,1]\n",
    "FP = cm[0,1]\n",
    "FN = cm[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy : 0.5629\n"
     ]
    }
   ],
   "source": [
    "# print classification accuracy, same as test set score & model accuracy score\n",
    "\n",
    "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
    "print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification error : 0.4371\n"
     ]
    }
   ],
   "source": [
    "# print classification error\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "\n",
    "print('Classification error : {0:0.4f}'.format(classification_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "pos_label=1 is not a valid label. It should be one of ['0', '1']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mc/1k6qg5js1x31mqzdq17v2yym0000gn/T/ipykernel_78626/1068738194.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# f1-score is always lower than accuracy measures, they embed precision and recall into their computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F1 Score: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \"\"\"\n\u001b[0;32m-> 1071\u001b[0;31m     return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n\u001b[0m\u001b[1;32m   1072\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \"\"\"\n\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m     _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[1;32m   1196\u001b[0m                                                  \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1462\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1464\u001b[0;31m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[1;32m   1465\u001b[0m                                     pos_label)\n\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpresent_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpresent_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m   1286\u001b[0m                         \u001b[0;34mf\"pos_label={pos_label} is not a valid label. It \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m                         \u001b[0;34mf\"should be one of {present_labels}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: pos_label=1 is not a valid label. It should be one of ['0', '1']"
     ]
    }
   ],
   "source": [
    "# f1-score is always lower than accuracy measures, they embed precision and recall into their computation\n",
    "print('F1 Score: %.3f' % f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
